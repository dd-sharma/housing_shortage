{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94af524f-5bea-473c-a89a-3894f9893be6",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fddfc5-45a4-45e8-aef2-261e28b36f67",
   "metadata": {},
   "source": [
    "## Affordability Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595873e4-e909-4618-bb32-ea73ed53c203",
   "metadata": {},
   "source": [
    "**Dataset: Housing Costs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaf7042f-ead8-4dda-998e-f9b84815c86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb72429e-5001-4be1-b46d-938fa63a7ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relative input and output paths\n",
    "input_file_path = \"../data/clean_data/affordability_metrics/housing_costs/metro_housing_prices.csv\"\n",
    "output_file_path = \"../data/preprocessed_data/affordability_metrics/housing_costs/metro_housing_prices_preprocessed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3c467d-5f79-4d0a-bec7-cd1a7f8bc6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(os.path.dirname(output_file_path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e7b2a4-abf1-495a-835f-55d53a29112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the data\n",
    "housing_prices_df = pd.read_csv(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3c9697-4562-4c6a-8c32-7c3aa1f8bfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert data types\n",
    "# Convert 'Month of Period End' to datetime\n",
    "housing_prices_df['Month of Period End'] = pd.to_datetime(housing_prices_df['Month of Period End'])\n",
    "\n",
    "# Convert numerical-like object columns to floats after removing commas\n",
    "for col in ['Homes Sold', 'New Listings', 'Inventory']:\n",
    "    housing_prices_df[col] = housing_prices_df[col].replace({',': ''}, regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c59edb5-9426-47f4-8724-a7cf75c4834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Handle missing values\n",
    "# Forward-fill for time-series continuity\n",
    "housing_prices_df.sort_values(by=['city', 'Month of Period End'], inplace=True)\n",
    "housing_prices_df.fillna(method='ffill', inplace=True)\n",
    "housing_prices_df.fillna(method='bfill', inplace=True)  # Back-fill as a fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04957ca4-e311-4037-87c8-378490671f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Feature Engineering\n",
    "# Add lagged features for 'Median Sale Price'\n",
    "housing_prices_df['Median Sale Price Lag1'] = housing_prices_df.groupby('city')['Median Sale Price'].shift(1)\n",
    "\n",
    "# Add rolling averages (3-month rolling mean for 'Median Sale Price')\n",
    "housing_prices_df['Median Sale Price Rolling3'] = housing_prices_df.groupby('city')['Median Sale Price'].rolling(window=3).mean().reset_index(0, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f4e80f-2923-44f6-a98d-192d988dbf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Normalize Data\n",
    "# Scale numerical columns (optional, depending on modeling approach)\n",
    "# Skipping normalization here, but can be added later as needed\n",
    "\n",
    "# Step 6: Save preprocessed data\n",
    "housing_prices_df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5695cc0-8ad2-4c50-85c1-0138fdd0eadb",
   "metadata": {},
   "source": [
    "**Dataset: Cost Burden**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ba826e-b447-40d4-95d8-558eb50ead58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relative input and output paths\n",
    "input_dir = \"../data/clean_data/affordability_metrics/cost_burden\"\n",
    "output_file_path = \"../data/preprocessed_data/affordability_metrics/cost_burden/cost_burden_preprocessed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3551529-da58-4a48-bda9-c48a8adf7249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(os.path.dirname(output_file_path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd40256-380d-4b84-90b2-a67c36ef349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and merge all cost burden files into a single DataFrame\n",
    "all_cost_burden_dfs = []\n",
    "\n",
    "for file_name in os.listdir(input_dir):\n",
    "    file_path = os.path.join(input_dir, file_name)\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['source_file'] = file_name  # Add source file information for traceability\n",
    "        all_cost_burden_dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "merged_cost_burden_df = pd.concat(all_cost_burden_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7241c387-4a62-4fe3-8781-511a775bea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Transform the 'year' column into a representative midpoint year\n",
    "def calculate_midpoint(year_range):\n",
    "    start_year, end_year = map(int, year_range.split('-'))\n",
    "    return (start_year + end_year) // 2\n",
    "\n",
    "merged_cost_burden_df['year'] = merged_cost_burden_df['year'].apply(calculate_midpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a052d08-5a6e-4e22-88b6-8cecd4f1ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Handle missing values\n",
    "# Fill missing values using forward fill and backward fill\n",
    "merged_cost_burden_df.fillna(method='ffill', inplace=True)\n",
    "merged_cost_burden_df.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe065fa9-ccb9-497e-be53-51a5dffc13fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Save the preprocessed data to a CSV file\n",
    "merged_cost_burden_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Confirm the process is complete\n",
    "print(f\"Preprocessed cost burden data has been saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49eb520-29fb-4f84-ad35-f0675474dea6",
   "metadata": {},
   "source": [
    "## Housing Supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28c42c2-06f1-412d-998c-d422703100b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relative input and output paths\n",
    "input_file_path = \"../data/clean_data/housing_supply/residential_construction_permits_2000_2022.csv\"\n",
    "output_file_path = \"../data/preprocessed_data/housing_supply/residential_construction_permits_2000_2022.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5ecb52-e204-43ee-a6fe-79e101af7a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(os.path.dirname(output_file_path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0afdf0-13f9-4aee-a712-e98a35e5da6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the data\n",
    "housing_supply_df = pd.read_csv(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01b1036-8502-409d-8eef-1ebc4fd253b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Reshape data from wide to long format\n",
    "# Identify columns to melt (years)\n",
    "id_vars = ['GEOID', 'NAME', 'STATE_NAME']\n",
    "value_vars = [col for col in housing_supply_df.columns if col not in id_vars]\n",
    "\n",
    "# Melt the dataset into long format\n",
    "housing_supply_long = housing_supply_df.melt(\n",
    "    id_vars=id_vars,\n",
    "    value_vars=value_vars,\n",
    "    var_name='Year_Permit_Type',\n",
    "    value_name='Permits'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3508e9c9-a6d9-4f5f-8820-804e9b4559a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Split 'Year_Permit_Type' into 'Year' and 'Permit_Type'\n",
    "housing_supply_long[['Permit_Type', 'Year']] = housing_supply_long['Year_Permit_Type'].str.extract(r'(.+)_(\\d{4})')\n",
    "\n",
    "# Convert 'Year' to an integer\n",
    "housing_supply_long['Year'] = housing_supply_long['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e53dba-3bdf-4f0f-87f6-8471174bdfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Handle missing values\n",
    "# Forward-fill and backward-fill missing values grouped by region\n",
    "housing_supply_long.sort_values(by=['GEOID', 'Year'], inplace=True)\n",
    "housing_supply_long['Permits'] = housing_supply_long.groupby('GEOID')['Permits'].transform(\n",
    "    lambda group: group.fillna(method='ffill').fillna(method='bfill')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007206bf-6bc7-4ac6-b4c4-08fd20deea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Feature engineering\n",
    "# Add rolling average for permits (3-year rolling mean)\n",
    "housing_supply_long['Rolling_Avg_Permits'] = housing_supply_long.groupby(['GEOID', 'Permit_Type'])['Permits'].transform(\n",
    "    lambda x: x.rolling(window=3, min_periods=1).mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9b3306-3966-4810-b1fa-3128d4e24bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Save preprocessed data\n",
    "housing_supply_long.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bdd459-4af1-4de0-9603-4ea1ce8152d1",
   "metadata": {},
   "source": [
    "## Demand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238ec917-e795-4502-98ac-ca2f41bd4a5c",
   "metadata": {},
   "source": [
    "**Dataset: Unemployment Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebcdfbf-dc8b-46ce-9e92-3bbacd1a590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "input_file_path = \"../data/clean_data/demand/economic/unemployment_rate/msa_unemployment.csv\"\n",
    "output_file_path = \"../data/preprocessed_data/demand/economic/unemployment_rate/msa_unemployment.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0896c89-bf88-474e-8f4a-da84dde5cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the dataset\n",
    "unemployment_rate_df = pd.read_csv(input_file_path)\n",
    "\n",
    "# Step 2: Convert `DATE` column to datetime format\n",
    "unemployment_rate_df['DATE'] = pd.to_datetime(unemployment_rate_df['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac082c5-0bfa-4701-87c1-3bffff1a6941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Handle missing data\n",
    "# Set 'DATE' as the index for time-based interpolation\n",
    "unemployment_rate_df.set_index('DATE', inplace=True)\n",
    "\n",
    "# Use linear interpolation with respect to the index\n",
    "unemployment_rate_df.interpolate(method='linear', inplace=True)\n",
    "\n",
    "# Reset the index back to default\n",
    "unemployment_rate_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b514d59-d6b6-49b8-a94d-88c3be0c8da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Reshape data to long format\n",
    "unemployment_rate_long = unemployment_rate_df.melt(\n",
    "    id_vars=['DATE'],\n",
    "    var_name='Metro_Area_Code',\n",
    "    value_name='Unemployment_Rate'\n",
    ")\n",
    "\n",
    "# Step 5: Save preprocessed data\n",
    "os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "unemployment_rate_long.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display a preview of the preprocessed data\n",
    "print(unemployment_rate_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85696b5-2c15-4ba5-93d9-d94ca7bc6fce",
   "metadata": {},
   "source": [
    "**Dataset: Wages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1100ec2c-85f7-4418-b709-f64535ad2f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "input_file_path = \"../data/clean_data/demand/economic/wages/msa_wages.csv\"\n",
    "output_file_path = \"../data/preprocessed_data/demand/economic/wages/msa_wages.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6d5ee2-cf98-4c4a-a4e6-bd5d545e39ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the dataset\n",
    "wages_df = pd.read_csv(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2298df-3e01-429b-aee0-dc1ab954bc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert `DATE` column to datetime format\n",
    "wages_df['DATE'] = pd.to_datetime(wages_df['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0a4b59-9b0a-4705-876a-db567d969c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Handle missing data\n",
    "# Set 'DATE' as the index for time-based interpolation\n",
    "wages_df.set_index('DATE', inplace=True)\n",
    "\n",
    "# Use linear interpolation to fill missing values\n",
    "wages_df.interpolate(method='linear', inplace=True)\n",
    "\n",
    "# Reset the index back to default\n",
    "wages_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc5e7d5-6d68-43f2-9650-545f0f6841d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Reshape data to long format\n",
    "wages_long = wages_df.melt(\n",
    "    id_vars=['DATE'],\n",
    "    var_name='Metro_Area_Code',\n",
    "    value_name='Average_Weekly_Wage'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193885b2-c293-44e5-8586-6a89c9bb3b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Save preprocessed data\n",
    "os.makedirs(\"../data/preprocessed_data/demand/economic/unemployment_rate\", exist_ok=True)\n",
    "wages_long.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display a preview of the preprocessed data\n",
    "print(wages_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a8a7fb-ce60-43a3-b6d6-054eb17137af",
   "metadata": {},
   "source": [
    "### Migration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1db1a6b2-dbdd-4d10-831a-3b530e553047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "input_file_path = \"../data/clean_data/demand/migration\"\n",
    "output_file_path = \"../data/preprocessed_data/demand/migration/migration_combined.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0deceb4f-20ba-4e1c-b3fa-ad3ae86d5c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: List all CSV files in the directory\n",
    "migration_files = [\n",
    "    os.path.join(root, file)\n",
    "    for root, _, files in os.walk(input_file_path)\n",
    "    for file in files if file.endswith('.csv')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f04bf24-65f5-43c0-b113-c6554f850bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined migration data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load and combine all migration files\n",
    "migration_dfs = []\n",
    "\n",
    "for file_path in migration_files:\n",
    "    # Extract the year from the file name\n",
    "    year = os.path.basename(file_path).split('_')[-1].split('.')[0]\n",
    "    \n",
    "    try:\n",
    "        # Load the file\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Check if the file is not empty and has valid columns\n",
    "        if not df.empty and 'NAME' in df.columns:\n",
    "            df['Year'] = int(year)  # Add a `Year` column\n",
    "            migration_dfs.append(df)\n",
    "        else:\n",
    "            print(f\"Skipping file with issues: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file {file_path}: {e}\")\n",
    "\n",
    "# Combine all dataframes\n",
    "if migration_dfs:\n",
    "    combined_migration_df = pd.concat(migration_dfs, ignore_index=True)\n",
    "    print(\"Combined migration data loaded successfully.\")\n",
    "else:\n",
    "    print(\"No valid migration files found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b265d5c5-07e0-4834-99c1-1402b29994de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ../data/clean_data/demand/migration\\inflow-outflow_2005.csv\n",
      "                              NAME  B07201_014E  B07201_013E  B07201_012E  \\\n",
      "0  San Luis Obispo-Paso Robles, CA        899.0        200.0        778.0   \n",
      "1    Santa Barbara-Santa Maria, CA       2725.0          0.0        166.0   \n",
      "2       Santa Cruz-Watsonville, CA       2091.0        101.0        534.0   \n",
      "3                     Santa Fe, NM        935.0        432.0       4543.0   \n",
      "4          Santa Rosa-Petaluma, CA       1653.0        467.0        521.0   \n",
      "\n",
      "   B07201_011E  B07201_010E  B07201_009E  B07201_008E  B07201_007E  \\\n",
      "0        553.0       1331.0      10085.0       6401.0      16486.0   \n",
      "1        375.0        541.0      11348.0      12246.0      23594.0   \n",
      "2         58.0        592.0       4430.0       5159.0       9589.0   \n",
      "3        364.0       4907.0       2301.0       5354.0       7655.0   \n",
      "4        882.0       1403.0       5506.0       8401.0      13907.0   \n",
      "\n",
      "   B07201_006E  B07201_005E  B07201_004E  B07201_003E  B07201_002E  \\\n",
      "0      21954.0      12722.0      34676.0      52693.0     183207.0   \n",
      "1      20148.0      31932.0      52080.0      76215.0     298263.0   \n",
      "2       9915.0      20154.0      30069.0      40351.0     193922.0   \n",
      "3       1465.0      14703.0      16168.0      29162.0     107068.0   \n",
      "4      26116.0      32632.0      58748.0      74525.0     371327.0   \n",
      "\n",
      "   B07201_001E  \n",
      "0     236799.0  \n",
      "1     377203.0  \n",
      "2     236364.0  \n",
      "3     137165.0  \n",
      "4     447505.0  \n",
      "Number of rows: 500\n",
      "File: ../data/clean_data/demand/migration\\inflow-outflow_2006.csv\n",
      "                              NAME  B07201_014E  B07201_013E  B07201_012E  \\\n",
      "0                Elizabethtown, KY       1832.0        803.0        496.0   \n",
      "1               Elkhart-Goshen, IN       2638.0        145.0       1586.0   \n",
      "2                       Elmira, NY        246.0        540.0        489.0   \n",
      "3                      El Paso, TX       9262.0        417.0        792.0   \n",
      "4  Enterprise-Ozark, AL Micro Area          NaN          NaN          NaN   \n",
      "\n",
      "   B07201_011E  B07201_010E  B07201_009E  B07201_008E  B07201_007E  \\\n",
      "0        741.0       1237.0       3856.0       2398.0       6254.0   \n",
      "1        749.0       2335.0       3057.0       3373.0       6430.0   \n",
      "2       1087.0       1576.0       1927.0       1265.0       3192.0   \n",
      "3       1302.0       2094.0      10988.0      13369.0      24357.0   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   B07201_006E  B07201_005E  B07201_004E  B07201_003E  B07201_002E  \\\n",
      "0       6345.0       3460.0       9805.0      18099.0      88092.0   \n",
      "1       4878.0      16468.0      21346.0      30256.0     161879.0   \n",
      "2       4348.0       6083.0      10431.0      15739.0      71394.0   \n",
      "3       5144.0      64987.0      70131.0      96999.0     616434.0   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   B07201_001E  \n",
      "0     108023.0  \n",
      "1     194773.0  \n",
      "2      87379.0  \n",
      "3     722695.0  \n",
      "4          NaN  \n",
      "Number of rows: 507\n",
      "File: ../data/clean_data/demand/migration\\inflow-outflow_2007.csv\n",
      "                        NAME  B07201_014E  B07201_013E  B07201_012E  \\\n",
      "0   Galesburg, IL Micro Area          NaN          NaN          NaN   \n",
      "1      Gallup, NM Micro Area          NaN          NaN          NaN   \n",
      "2  Gettysburg, PA Micro Area          NaN          NaN          NaN   \n",
      "3            Glens Falls, NY        504.0        177.0       1090.0   \n",
      "4              Goldsboro, NC        729.0        443.0        951.0   \n",
      "\n",
      "   B07201_011E  B07201_010E  B07201_009E  B07201_008E  B07201_007E  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "3        361.0       1451.0       2830.0       2166.0       4996.0   \n",
      "4        635.0       1586.0       1526.0       2147.0       3673.0   \n",
      "\n",
      "   B07201_006E  B07201_005E  B07201_004E  B07201_003E  B07201_002E  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "3       8943.0       1548.0      10491.0      17115.0     110001.0   \n",
      "4       4268.0       7013.0      11281.0      16983.0      94062.0   \n",
      "\n",
      "   B07201_001E  \n",
      "0          NaN  \n",
      "1          NaN  \n",
      "2          NaN  \n",
      "3     127620.0  \n",
      "4     111774.0  \n",
      "Number of rows: 510\n",
      "File: ../data/clean_data/demand/migration\\inflow-outflow_2008.csv\n",
      "                       NAME  B07201_014E  B07201_013E  B07201_012E  \\\n",
      "0            Fort Wayne, IN       1452.0        824.0       2580.0   \n",
      "1  Frankfort, KY Micro Area          NaN          NaN          NaN   \n",
      "2                Fresno, CA       8230.0       1322.0        302.0   \n",
      "3               Gadsden, AL          0.0        306.0       1227.0   \n",
      "4           Gainesville, FL       1402.0        841.0        602.0   \n",
      "\n",
      "   B07201_011E  B07201_010E  B07201_009E  B07201_008E  B07201_007E  \\\n",
      "0       1501.0       4081.0       5523.0       4333.0       9856.0   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2        748.0       1050.0      13082.0      14679.0      27761.0   \n",
      "3        102.0       1329.0       3995.0       1545.0       5540.0   \n",
      "4        130.0        732.0      13499.0       7780.0      21279.0   \n",
      "\n",
      "   B07201_006E  B07201_005E  B07201_004E  B07201_003E  B07201_002E  \\\n",
      "0      12861.0      26023.0      38884.0      53645.0     348940.0   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2      36837.0      72096.0     108933.0     139066.0     745631.0   \n",
      "3       6238.0       5744.0      11982.0      19157.0      83197.0   \n",
      "4       7653.0      23762.0      31415.0      54267.0     196708.0   \n",
      "\n",
      "   B07201_001E  \n",
      "0     404037.0  \n",
      "1          NaN  \n",
      "2     892927.0  \n",
      "3     102354.0  \n",
      "4     252377.0  \n",
      "Number of rows: 512\n",
      "File: ../data/clean_data/demand/migration\\inflow-outflow_2009.csv\n",
      "                                     NAME  B07201_014E  B07201_013E  \\\n",
      "0                             Decatur, IL        254.0        837.0   \n",
      "1  Deltona-Daytona Beach-Ormond Beach, FL       2052.0       1090.0   \n",
      "2            Denver-Aurora-Broomfield, CO      12267.0       6492.0   \n",
      "3          Des Moines-West Des Moines, IA       3065.0       2805.0   \n",
      "4              Detroit-Warren-Livonia, MI      26605.0       5799.0   \n",
      "\n",
      "   B07201_012E  B07201_011E  B07201_010E  B07201_009E  B07201_008E  \\\n",
      "0        381.0         18.0        399.0       1359.0       1079.0   \n",
      "1       2080.0       1160.0       3240.0      19236.0       7802.0   \n",
      "2       4627.0       5711.0      10338.0      49717.0      47220.0   \n",
      "3       2362.0       1673.0       4035.0       5406.0       9978.0   \n",
      "4       3622.0       4535.0       8157.0      35574.0      25822.0   \n",
      "\n",
      "   B07201_007E  B07201_006E  B07201_005E  B07201_004E  B07201_003E  \\\n",
      "0       2438.0       1402.0      10363.0      11765.0      15439.0   \n",
      "1      27038.0      22201.0      13828.0      36029.0      67397.0   \n",
      "2      96937.0     165736.0     156873.0     322609.0     436376.0   \n",
      "3      15384.0      29791.0      41773.0      71564.0      93788.0   \n",
      "4      61396.0     259711.0     235426.0     495137.0     570489.0   \n",
      "\n",
      "   B07201_002E  B07201_001E  \n",
      "0      91326.0     107019.0  \n",
      "1     421187.0     490636.0  \n",
      "2    2066312.0    2514955.0  \n",
      "3     458637.0     555490.0  \n",
      "4    3755433.0    4352527.0  \n",
      "Number of rows: 517\n"
     ]
    }
   ],
   "source": [
    "# Debugging: Print the paths and inspect a few files manually\n",
    "for file_path in migration_files[:5]:  # Check the first 5 files\n",
    "    try:\n",
    "        # Load the file\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"File: {file_path}\")\n",
    "        print(df.head())  # Preview the content\n",
    "        print(f\"Number of rows: {len(df)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4bf5f6b-4da9-4b24-b9f2-b926534725cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deeps\\AppData\\Local\\Temp\\ipykernel_35696\\2084664700.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  combined_migration_df.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\deeps\\AppData\\Local\\Temp\\ipykernel_35696\\2084664700.py:4: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  combined_migration_df.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Handle missing values\n",
    "# Fill missing values using forward-fill and backward-fill methods\n",
    "combined_migration_df.fillna(method='ffill', inplace=True)\n",
    "combined_migration_df.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "393fb239-88af-446e-9d84-f9f392cfd53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              NAME  B07201_014E  B07201_013E  B07201_012E  \\\n",
      "0  San Luis Obispo-Paso Robles, CA        899.0        200.0        778.0   \n",
      "1    Santa Barbara-Santa Maria, CA       2725.0          0.0        166.0   \n",
      "2       Santa Cruz-Watsonville, CA       2091.0        101.0        534.0   \n",
      "3                     Santa Fe, NM        935.0        432.0       4543.0   \n",
      "4          Santa Rosa-Petaluma, CA       1653.0        467.0        521.0   \n",
      "\n",
      "   B07201_011E  B07201_010E  B07201_009E  B07201_008E  B07201_007E  \\\n",
      "0        553.0       1331.0      10085.0       6401.0      16486.0   \n",
      "1        375.0        541.0      11348.0      12246.0      23594.0   \n",
      "2         58.0        592.0       4430.0       5159.0       9589.0   \n",
      "3        364.0       4907.0       2301.0       5354.0       7655.0   \n",
      "4        882.0       1403.0       5506.0       8401.0      13907.0   \n",
      "\n",
      "   B07201_006E  B07201_005E  B07201_004E  B07201_003E  B07201_002E  \\\n",
      "0      21954.0      12722.0      34676.0      52693.0     183207.0   \n",
      "1      20148.0      31932.0      52080.0      76215.0     298263.0   \n",
      "2       9915.0      20154.0      30069.0      40351.0     193922.0   \n",
      "3       1465.0      14703.0      16168.0      29162.0     107068.0   \n",
      "4      26116.0      32632.0      58748.0      74525.0     371327.0   \n",
      "\n",
      "   B07201_001E  Year  \n",
      "0     236799.0  2005  \n",
      "1     377203.0  2005  \n",
      "2     236364.0  2005  \n",
      "3     137165.0  2005  \n",
      "4     447505.0  2005  \n"
     ]
    }
   ],
   "source": [
    "# Step 4: Save the preprocessed data\n",
    "os.makedirs(\"../data/preprocessed_data/demand/migration\", exist_ok=True)\n",
    "combined_migration_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display a preview of the preprocessed dataset\n",
    "print(combined_migration_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a69d15f-9946-4aa8-a0dd-02ba683b23b8",
   "metadata": {},
   "source": [
    "### Population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf20c66-441b-4cb0-b831-67adeffa42f6",
   "metadata": {},
   "source": [
    "**Dataset: Historical**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b412f65-7a6b-440d-aebf-4a643e276f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "input_file_path = \"../data/clean_data/demand/population/historical/msa_historical.csv\"\n",
    "output_file_path = \"../data/preprocessed_data/demand/population/historical/msa_historical.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0468887f-d5b5-4dc0-a321-cd1d512ebffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the dataset\n",
    "historical_population_df = pd.read_csv(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35e17a31-84c1-4971-abe7-3f843faf6ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert `DATE` column to datetime format\n",
    "historical_population_df['DATE'] = pd.to_datetime(historical_population_df['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70f2aa21-9b22-4bc7-8625-a5b1fc6fe485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Save the preprocessed data\n",
    "os.makedirs(\"../data/preprocessed_data/demand/population/historical\", exist_ok=True)\n",
    "historical_population_df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6af972f-4b7b-4da0-8089-386e3afdbd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DATE  POPULATION                            MSA\n",
      "0 2000-01-01    4281.905  atlanta-sandy_springs-roswell\n",
      "1 2001-01-01    4432.950  atlanta-sandy_springs-roswell\n",
      "2 2002-01-01    4555.490  atlanta-sandy_springs-roswell\n",
      "3 2003-01-01    4673.146  atlanta-sandy_springs-roswell\n",
      "4 2004-01-01    4802.300  atlanta-sandy_springs-roswell\n"
     ]
    }
   ],
   "source": [
    "# Display a preview of the preprocessed dataset\n",
    "print(historical_population_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7718b2-6bb7-4b45-a990-a1aebc785617",
   "metadata": {},
   "source": [
    "**Dataset: Estimated**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f4c783d-487c-4e89-8fbc-b87b5ded4e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "input_file_path = \"../data/clean_data/demand/population/projected/msa_projected.csv\"\n",
    "output_file_path = \"../data/preprocessed_data/demand/population/projected/msa_projected.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "473cce85-1b32-484a-8aa9-b46b0a2ecbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the dataset\n",
    "projected_population_df = pd.read_csv(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d34813b8-c1c8-4a7b-8fb9-c63069635f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deeps\\AppData\\Local\\Temp\\ipykernel_35696\\1426545730.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  projected_population_df.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\deeps\\AppData\\Local\\Temp\\ipykernel_35696\\1426545730.py:4: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  projected_population_df.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Handle missing data\n",
    "# Fill missing values with forward-fill and backward-fill\n",
    "projected_population_df.fillna(method='ffill', inplace=True)\n",
    "projected_population_df.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3cfe3da3-b833-4195-a182-64886e8a82c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Reshape data to long format\n",
    "projected_population_long = projected_population_df.melt(\n",
    "    id_vars=['Geographic Area', 'Base Population (2020)'],\n",
    "    var_name='Year',\n",
    "    value_name='Population'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1db6d6c8-c4e3-43bc-9966-bff1619f5247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year from the 'Year' column\n",
    "projected_population_long['Year'] = projected_population_long['Year'].str.extract(r'(\\d{4})').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "67cdcd18-52e4-44a3-948f-b005263d9af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Geographic Area  Base Population (2020)  Year  Population\n",
      "0                  Abilene, TX                176562.0  2020    176883.0\n",
      "1                    Akron, OH                702225.0  2020    701674.0\n",
      "2                   Albany, GA                148915.0  2020    148249.0\n",
      "3                   Albany, OR                128611.0  2020    128981.0\n",
      "4  Albany-Schenectady-Troy, NY                899247.0  2020    899724.0\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Save the preprocessed data\n",
    "os.makedirs(\"../data/preprocessed_data/demand/population/projected\", exist_ok=True)\n",
    "projected_population_long.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display a preview of the preprocessed dataset\n",
    "print(projected_population_long.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
